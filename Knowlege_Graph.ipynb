{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","authorship_tag":"ABX9TyOBE3ZZtgRPDFsik5v6Le8U"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"gpuClass":"standard"},"cells":[{"cell_type":"code","source":["! pip install torch transformers numpy pandas seaborn matplotlib tqdm wikipedia"],"metadata":{"id":"fXDnaoVvrGQk","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1684478227356,"user_tz":-120,"elapsed":5077,"user":{"displayName":"Ramona Koksa","userId":"07108763038169928960"}},"outputId":"abb17bec-c075-4ba8-a2a6-5e14bdd94a2c"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.0.1+cu118)\n","Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.29.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.22.4)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n","Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (0.12.2)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.65.0)\n","Requirement already satisfied: wikipedia in /usr/local/lib/python3.10/dist-packages (1.4.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.12.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.11.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (3.25.2)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (16.0.5)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.14.1)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2022.7.1)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.0.7)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.11.0)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.39.3)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.4)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (8.4.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.0.9)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from wikipedia) (4.11.2)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.4.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->wikipedia) (2.4.1)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.2)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"]}]},{"cell_type":"code","source":["from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n","import math\n","import torch\n","import wikipedia\n","import pandas as pd\n","import torch\n","from transformers import AutoTokenizer, GPTNeoForCausalLM, AutoModelForSeq2SeqLM"],"metadata":{"id":"YmZBL0zJtalH","executionInfo":{"status":"ok","timestamp":1684478232212,"user_tz":-120,"elapsed":4865,"user":{"displayName":"Ramona Koksa","userId":"07108763038169928960"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["tokenizer = AutoTokenizer.from_pretrained(\"Babelscape/rebel-large\")\n","model = AutoModelForSeq2SeqLM.from_pretrained(\"Babelscape/rebel-large\")"],"metadata":{"id":"cZ1kF0Uos1iK","executionInfo":{"status":"ok","timestamp":1684478242970,"user_tz":-120,"elapsed":10762,"user":{"displayName":"Ramona Koksa","userId":"07108763038169928960"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["def extract_relations_from_model_output(text):\n","    relations = []\n","    relation, subject, relation, object_ = '', '', '', ''\n","    text = text.strip()\n","    current = 'x'\n","    text_replaced = text.replace(\"<s>\", \"\").replace(\"<pad>\", \"\").replace(\"</s>\", \"\")\n","    for token in text_replaced.split():\n","        if token == \"<triplet>\":\n","            current = 't'\n","            if relation != '':\n","                relations.append({\n","                    'head': subject.strip(),\n","                    'type': relation.strip(),\n","                    'tail': object_.strip()\n","                })\n","                relation = ''\n","            subject = ''\n","        elif token == \"<subj>\":\n","            current = 's'\n","            if relation != '':\n","                relations.append({\n","                    'head': subject.strip(),\n","                    'type': relation.strip(),\n","                    'tail': object_.strip()\n","                })\n","            object_ = ''\n","        elif token == \"<obj>\":\n","            current = 'o'\n","            relation = ''\n","        else:\n","            if current == 't':\n","                subject += ' ' + token\n","            elif current == 's':\n","                object_ += ' ' + token\n","            elif current == 'o':\n","                relation += ' ' + token\n","    if subject != '' and relation != '' and object_ != '':\n","        relations.append({\n","            'head': subject.strip(),\n","            'type': relation.strip(),\n","            'tail': object_.strip()\n","        })\n","    return relations"],"metadata":{"id":"E4VKoSU5sTfm","executionInfo":{"status":"ok","timestamp":1684478242971,"user_tz":-120,"elapsed":19,"user":{"displayName":"Ramona Koksa","userId":"07108763038169928960"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["class KB():\n","    def __init__(self):\n","        self.entities = {}\n","        self.relations = []\n","\n","    def are_relations_equal(self, r1, r2):\n","        return all(r1[attr] == r2[attr] for attr in [\"head\", \"type\", \"tail\"])\n","\n","    def exists_relation(self, r1):\n","        return any(self.are_relations_equal(r1, r2) for r2 in self.relations)\n","\n","    def merge_relations(self, r1):\n","        r2 = [r for r in self.relations\n","              if self.are_relations_equal(r1, r)][0]\n","        spans_to_add = [span for span in r1[\"meta\"][\"spans\"]\n","                        if span not in r2[\"meta\"][\"spans\"]]\n","        r2[\"meta\"][\"spans\"] += spans_to_add\n","\n","    def get_wikipedia_data(self, candidate_entity):\n","        try:\n","            page = wikipedia.page(candidate_entity, auto_suggest=False)\n","            entity_data = {\n","                \"title\": page.title,\n","                \"url\": page.url,\n","                \"summary\": page.summary\n","            }\n","            return entity_data\n","        except:\n","            return None\n","\n","    def add_entity(self, e):\n","        self.entities[e[\"title\"]] = {k:v for k,v in e.items() if k != \"title\"}\n","\n","    def add_relation(self, r):\n","        # check on wikipedia\n","        candidate_entities = [r[\"head\"], r[\"tail\"]]\n","        entities = [self.get_wikipedia_data(ent) for ent in candidate_entities]\n","\n","        # if one entity does not exist, stop\n","        if any(ent is None for ent in entities):\n","            return\n","\n","        # manage new entities\n","        for e in entities:\n","            self.add_entity(e)\n","\n","        # rename relation entities with their wikipedia titles\n","        r[\"head\"] = entities[0][\"title\"]\n","        r[\"tail\"] = entities[1][\"title\"]\n","\n","        # manage new relation\n","        if not self.exists_relation(r):\n","            self.relations.append(r)\n","        else:\n","            self.merge_relations(r)\n","\n","    def print(self):\n","        print(\"Entities:\")\n","        for e in self.entities.items():\n","            print(f\"  {e}\")\n","        print(\"Relations:\")\n","        for r in self.relations:\n","            print(f\"  {r}\")"],"metadata":{"id":"zPVMmY1ItNMv","executionInfo":{"status":"ok","timestamp":1684478242971,"user_tz":-120,"elapsed":18,"user":{"displayName":"Ramona Koksa","userId":"07108763038169928960"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["def from_text_to_kb(text, span_length=128, verbose=False):\n","    # tokenize whole text\n","    inputs = tokenizer([text], return_tensors=\"pt\")\n","\n","    # compute span boundaries\n","    num_tokens = len(inputs[\"input_ids\"][0])\n","    if verbose:\n","        print(f\"Input has {num_tokens} tokens\")\n","    num_spans = math.ceil(num_tokens / span_length)\n","    if verbose:\n","        print(f\"Input has {num_spans} spans\")\n","    overlap = math.ceil((num_spans * span_length - num_tokens) / \n","                        max(num_spans - 1, 1))\n","    spans_boundaries = []\n","    start = 0\n","    for i in range(num_spans):\n","        spans_boundaries.append([start + span_length * i,\n","                                 start + span_length * (i + 1)])\n","        start -= overlap\n","    if verbose:\n","        print(f\"Span boundaries are {spans_boundaries}\")\n","\n","    # transform input with spans\n","    tensor_ids = [inputs[\"input_ids\"][0][boundary[0]:boundary[1]]\n","                  for boundary in spans_boundaries]\n","    tensor_masks = [inputs[\"attention_mask\"][0][boundary[0]:boundary[1]]\n","                    for boundary in spans_boundaries]\n","    inputs = {\n","        \"input_ids\": torch.stack(tensor_ids),\n","        \"attention_mask\": torch.stack(tensor_masks)\n","    }\n","\n","    # generate relations\n","    num_return_sequences = 3\n","    gen_kwargs = {\n","        \"max_length\": 256,\n","        \"length_penalty\": 0,\n","        \"num_beams\": 3,\n","        \"num_return_sequences\": num_return_sequences\n","    }\n","    generated_tokens = model.generate(\n","        **inputs,\n","        **gen_kwargs,\n","    )\n","\n","    # decode relations\n","    decoded_preds = tokenizer.batch_decode(generated_tokens,\n","                                           skip_special_tokens=False)\n","\n","    # create kb\n","    kb = KB()\n","    i = 0\n","    for sentence_pred in decoded_preds:\n","        current_span_index = i // num_return_sequences\n","        relations = extract_relations_from_model_output(sentence_pred)\n","        for relation in relations:\n","            relation[\"meta\"] = {\n","                \"spans\": [spans_boundaries[current_span_index]]\n","            }\n","            kb.add_relation(relation)\n","        i += 1\n","\n","    return kb"],"metadata":{"id":"1nVqf1fEsd-C","executionInfo":{"status":"ok","timestamp":1684478242971,"user_tz":-120,"elapsed":18,"user":{"displayName":"Ramona Koksa","userId":"07108763038169928960"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["df = pd.read_csv('output_final.csv', sep=';')\n","\n","data = []\n","\n","for index, row in df.iterrows():\n","  id = row['id']\n","  text = row['title']\n","  kb = from_text_to_kb(text, verbose=True)\n","  for r in kb.relations:\n","    data.append([id, r['head'], r['type'], r['tail']])\n","    ndf = pd.DataFrame(data, columns=['id', 'head', 'type', 'tail'])\n","  \n","ndf.to_csv('rebel_final.csv')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cvXzCorXtTc1","executionInfo":{"status":"ok","timestamp":1684479114388,"user_tz":-120,"elapsed":871434,"user":{"displayName":"Ramona Koksa","userId":"07108763038169928960"}},"outputId":"95501754-c56d-4cc4-be22-3fdbd569cab5"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Input has 18 tokens\n","Input has 1 spans\n","Span boundaries are [[0, 128]]\n","Input has 12 tokens\n","Input has 1 spans\n","Span boundaries are [[0, 128]]\n","Input has 51 tokens\n","Input has 1 spans\n","Span boundaries are [[0, 128]]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/wikipedia/wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n","\n","The code that caused this warning is on line 389 of the file /usr/local/lib/python3.10/dist-packages/wikipedia/wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n","\n","  lis = BeautifulSoup(html).find_all('li')\n"]},{"output_type":"stream","name":"stdout","text":["Input has 44 tokens\n","Input has 1 spans\n","Span boundaries are [[0, 128]]\n","Input has 55 tokens\n","Input has 1 spans\n","Span boundaries are [[0, 128]]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/wikipedia/wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n","\n","The code that caused this warning is on line 389 of the file /usr/local/lib/python3.10/dist-packages/wikipedia/wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n","\n","  lis = BeautifulSoup(html).find_all('li')\n"]},{"output_type":"stream","name":"stdout","text":["Input has 11 tokens\n","Input has 1 spans\n","Span boundaries are [[0, 128]]\n","Input has 22 tokens\n","Input has 1 spans\n","Span boundaries are [[0, 128]]\n","Input has 22 tokens\n","Input has 1 spans\n","Span boundaries are [[0, 128]]\n","Input has 18 tokens\n","Input has 1 spans\n","Span boundaries are [[0, 128]]\n","Input has 15 tokens\n","Input has 1 spans\n","Span boundaries are [[0, 128]]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/wikipedia/wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n","\n","The code that caused this warning is on line 389 of the file /usr/local/lib/python3.10/dist-packages/wikipedia/wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n","\n","  lis = BeautifulSoup(html).find_all('li')\n"]},{"output_type":"stream","name":"stdout","text":["Input has 19 tokens\n","Input has 1 spans\n","Span boundaries are [[0, 128]]\n","Input has 13 tokens\n","Input has 1 spans\n","Span boundaries are [[0, 128]]\n","Input has 13 tokens\n","Input has 1 spans\n","Span boundaries are [[0, 128]]\n","Input has 13 tokens\n","Input has 1 spans\n","Span boundaries are [[0, 128]]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/wikipedia/wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n","\n","The code that caused this warning is on line 389 of the file /usr/local/lib/python3.10/dist-packages/wikipedia/wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n","\n","  lis = BeautifulSoup(html).find_all('li')\n"]},{"output_type":"stream","name":"stdout","text":["Input has 24 tokens\n","Input has 1 spans\n","Span boundaries are [[0, 128]]\n","Input has 17 tokens\n","Input has 1 spans\n","Span boundaries are [[0, 128]]\n","Input has 17 tokens\n","Input has 1 spans\n","Span boundaries are [[0, 128]]\n","Input has 15 tokens\n","Input has 1 spans\n","Span boundaries are [[0, 128]]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/wikipedia/wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n","\n","The code that caused this warning is on line 389 of the file /usr/local/lib/python3.10/dist-packages/wikipedia/wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n","\n","  lis = BeautifulSoup(html).find_all('li')\n"]},{"output_type":"stream","name":"stdout","text":["Input has 21 tokens\n","Input has 1 spans\n","Span boundaries are [[0, 128]]\n","Input has 12 tokens\n","Input has 1 spans\n","Span boundaries are [[0, 128]]\n","Input has 15 tokens\n","Input has 1 spans\n","Span boundaries are [[0, 128]]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/wikipedia/wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n","\n","The code that caused this warning is on line 389 of the file /usr/local/lib/python3.10/dist-packages/wikipedia/wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n","\n","  lis = BeautifulSoup(html).find_all('li')\n"]},{"output_type":"stream","name":"stdout","text":["Input has 21 tokens\n","Input has 1 spans\n","Span boundaries are [[0, 128]]\n","Input has 16 tokens\n","Input has 1 spans\n","Span boundaries are [[0, 128]]\n","Input has 10 tokens\n","Input has 1 spans\n","Span boundaries are [[0, 128]]\n","Input has 8 tokens\n","Input has 1 spans\n","Span boundaries are [[0, 128]]\n","Input has 14 tokens\n","Input has 1 spans\n","Span boundaries are [[0, 128]]\n","Input has 18 tokens\n","Input has 1 spans\n","Span boundaries are [[0, 128]]\n","Input has 20 tokens\n","Input has 1 spans\n","Span boundaries are [[0, 128]]\n","Input has 9 tokens\n","Input has 1 spans\n","Span boundaries are [[0, 128]]\n","Input has 16 tokens\n","Input has 1 spans\n","Span boundaries are [[0, 128]]\n","Input has 20 tokens\n","Input has 1 spans\n","Span boundaries are [[0, 128]]\n","Input has 9 tokens\n","Input has 1 spans\n","Span boundaries are [[0, 128]]\n","Input has 10 tokens\n","Input has 1 spans\n","Span boundaries are [[0, 128]]\n","Input has 27 tokens\n","Input has 1 spans\n","Span boundaries are [[0, 128]]\n","Input has 17 tokens\n","Input has 1 spans\n","Span boundaries are [[0, 128]]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/wikipedia/wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n","\n","The code that caused this warning is on line 389 of the file /usr/local/lib/python3.10/dist-packages/wikipedia/wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n","\n","  lis = BeautifulSoup(html).find_all('li')\n"]},{"output_type":"stream","name":"stdout","text":["Input has 16 tokens\n","Input has 1 spans\n","Span boundaries are [[0, 128]]\n","Input has 8 tokens\n","Input has 1 spans\n","Span boundaries are [[0, 128]]\n","Input has 14 tokens\n","Input has 1 spans\n","Span boundaries are [[0, 128]]\n","Input has 17 tokens\n","Input has 1 spans\n","Span boundaries are [[0, 128]]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/wikipedia/wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n","\n","The code that caused this warning is on line 389 of the file /usr/local/lib/python3.10/dist-packages/wikipedia/wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n","\n","  lis = BeautifulSoup(html).find_all('li')\n"]},{"output_type":"stream","name":"stdout","text":["Input has 15 tokens\n","Input has 1 spans\n","Span boundaries are [[0, 128]]\n","Input has 19 tokens\n","Input has 1 spans\n","Span boundaries are [[0, 128]]\n","Input has 26 tokens\n","Input has 1 spans\n","Span boundaries are [[0, 128]]\n","Input has 16 tokens\n","Input has 1 spans\n","Span boundaries are [[0, 128]]\n","Input has 16 tokens\n","Input has 1 spans\n","Span boundaries are [[0, 128]]\n","Input has 25 tokens\n","Input has 1 spans\n","Span boundaries are [[0, 128]]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/wikipedia/wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n","\n","The code that caused this warning is on line 389 of the file /usr/local/lib/python3.10/dist-packages/wikipedia/wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n","\n","  lis = BeautifulSoup(html).find_all('li')\n"]},{"output_type":"stream","name":"stdout","text":["Input has 6 tokens\n","Input has 1 spans\n","Span boundaries are [[0, 128]]\n","Input has 8 tokens\n","Input has 1 spans\n","Span boundaries are [[0, 128]]\n","Input has 12 tokens\n","Input has 1 spans\n","Span boundaries are [[0, 128]]\n","Input has 8 tokens\n","Input has 1 spans\n","Span boundaries are [[0, 128]]\n","Input has 16 tokens\n","Input has 1 spans\n","Span boundaries are [[0, 128]]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/wikipedia/wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n","\n","The code that caused this warning is on line 389 of the file /usr/local/lib/python3.10/dist-packages/wikipedia/wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n","\n","  lis = BeautifulSoup(html).find_all('li')\n"]},{"output_type":"stream","name":"stdout","text":["Input has 15 tokens\n","Input has 1 spans\n","Span boundaries are [[0, 128]]\n","Input has 14 tokens\n","Input has 1 spans\n","Span boundaries are [[0, 128]]\n","Input has 15 tokens\n","Input has 1 spans\n","Span boundaries are [[0, 128]]\n","Input has 31 tokens\n","Input has 1 spans\n","Span boundaries are [[0, 128]]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/wikipedia/wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n","\n","The code that caused this warning is on line 389 of the file /usr/local/lib/python3.10/dist-packages/wikipedia/wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n","\n","  lis = BeautifulSoup(html).find_all('li')\n"]},{"output_type":"stream","name":"stdout","text":["Input has 9 tokens\n","Input has 1 spans\n","Span boundaries are [[0, 128]]\n","Input has 27 tokens\n","Input has 1 spans\n","Span boundaries are [[0, 128]]\n","Input has 18 tokens\n","Input has 1 spans\n","Span boundaries are [[0, 128]]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/wikipedia/wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n","\n","The code that caused this warning is on line 389 of the file /usr/local/lib/python3.10/dist-packages/wikipedia/wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n","\n","  lis = BeautifulSoup(html).find_all('li')\n"]},{"output_type":"stream","name":"stdout","text":["Input has 16 tokens\n","Input has 1 spans\n","Span boundaries are [[0, 128]]\n","Input has 15 tokens\n","Input has 1 spans\n","Span boundaries are [[0, 128]]\n","Input has 8 tokens\n","Input has 1 spans\n","Span boundaries are [[0, 128]]\n","Input has 14 tokens\n","Input has 1 spans\n","Span boundaries are [[0, 128]]\n","Input has 14 tokens\n","Input has 1 spans\n","Span boundaries are [[0, 128]]\n","Input has 14 tokens\n","Input has 1 spans\n","Span boundaries are [[0, 128]]\n","Input has 15 tokens\n","Input has 1 spans\n","Span boundaries are [[0, 128]]\n","Input has 18 tokens\n","Input has 1 spans\n","Span boundaries are [[0, 128]]\n","Input has 19 tokens\n","Input has 1 spans\n","Span boundaries are [[0, 128]]\n","Input has 11 tokens\n","Input has 1 spans\n","Span boundaries are [[0, 128]]\n","Input has 16 tokens\n","Input has 1 spans\n","Span boundaries are [[0, 128]]\n","Input has 11 tokens\n","Input has 1 spans\n","Span boundaries are [[0, 128]]\n","Input has 11 tokens\n","Input has 1 spans\n","Span boundaries are [[0, 128]]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/wikipedia/wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n","\n","The code that caused this warning is on line 389 of the file /usr/local/lib/python3.10/dist-packages/wikipedia/wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n","\n","  lis = BeautifulSoup(html).find_all('li')\n"]},{"output_type":"stream","name":"stdout","text":["Input has 16 tokens\n","Input has 1 spans\n","Span boundaries are [[0, 128]]\n","Input has 17 tokens\n","Input has 1 spans\n","Span boundaries are [[0, 128]]\n","Input has 17 tokens\n","Input has 1 spans\n","Span boundaries are [[0, 128]]\n","Input has 27 tokens\n","Input has 1 spans\n","Span boundaries are [[0, 128]]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/wikipedia/wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n","\n","The code that caused this warning is on line 389 of the file /usr/local/lib/python3.10/dist-packages/wikipedia/wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n","\n","  lis = BeautifulSoup(html).find_all('li')\n"]},{"output_type":"stream","name":"stdout","text":["Input has 12 tokens\n","Input has 1 spans\n","Span boundaries are [[0, 128]]\n","Input has 17 tokens\n","Input has 1 spans\n","Span boundaries are [[0, 128]]\n","Input has 13 tokens\n","Input has 1 spans\n","Span boundaries are [[0, 128]]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/wikipedia/wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n","\n","The code that caused this warning is on line 389 of the file /usr/local/lib/python3.10/dist-packages/wikipedia/wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n","\n","  lis = BeautifulSoup(html).find_all('li')\n"]},{"output_type":"stream","name":"stdout","text":["Input has 16 tokens\n","Input has 1 spans\n","Span boundaries are [[0, 128]]\n","Input has 9 tokens\n","Input has 1 spans\n","Span boundaries are [[0, 128]]\n","Input has 17 tokens\n","Input has 1 spans\n","Span boundaries are [[0, 128]]\n","Input has 11 tokens\n","Input has 1 spans\n","Span boundaries are [[0, 128]]\n","Input has 11 tokens\n","Input has 1 spans\n","Span boundaries are [[0, 128]]\n","Input has 18 tokens\n","Input has 1 spans\n","Span boundaries are [[0, 128]]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/wikipedia/wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n","\n","The code that caused this warning is on line 389 of the file /usr/local/lib/python3.10/dist-packages/wikipedia/wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n","\n","  lis = BeautifulSoup(html).find_all('li')\n"]},{"output_type":"stream","name":"stdout","text":["Input has 18 tokens\n","Input has 1 spans\n","Span boundaries are [[0, 128]]\n","Input has 15 tokens\n","Input has 1 spans\n","Span boundaries are [[0, 128]]\n","Input has 15 tokens\n","Input has 1 spans\n","Span boundaries are [[0, 128]]\n","Input has 15 tokens\n","Input has 1 spans\n","Span boundaries are [[0, 128]]\n","Input has 9 tokens\n","Input has 1 spans\n","Span boundaries are [[0, 128]]\n","Input has 42 tokens\n","Input has 1 spans\n","Span boundaries are [[0, 128]]\n","Input has 42 tokens\n","Input has 1 spans\n","Span boundaries are [[0, 128]]\n","Input has 42 tokens\n","Input has 1 spans\n","Span boundaries are [[0, 128]]\n","Input has 42 tokens\n","Input has 1 spans\n","Span boundaries are [[0, 128]]\n","Input has 42 tokens\n","Input has 1 spans\n","Span boundaries are [[0, 128]]\n","Input has 42 tokens\n","Input has 1 spans\n","Span boundaries are [[0, 128]]\n","Input has 16 tokens\n","Input has 1 spans\n","Span boundaries are [[0, 128]]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/wikipedia/wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n","\n","The code that caused this warning is on line 389 of the file /usr/local/lib/python3.10/dist-packages/wikipedia/wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n","\n","  lis = BeautifulSoup(html).find_all('li')\n"]},{"output_type":"stream","name":"stdout","text":["Input has 22 tokens\n","Input has 1 spans\n","Span boundaries are [[0, 128]]\n","Input has 16 tokens\n","Input has 1 spans\n","Span boundaries are [[0, 128]]\n","Input has 61 tokens\n","Input has 1 spans\n","Span boundaries are [[0, 128]]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/wikipedia/wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n","\n","The code that caused this warning is on line 389 of the file /usr/local/lib/python3.10/dist-packages/wikipedia/wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n","\n","  lis = BeautifulSoup(html).find_all('li')\n"]},{"output_type":"stream","name":"stdout","text":["Input has 61 tokens\n","Input has 1 spans\n","Span boundaries are [[0, 128]]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/wikipedia/wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n","\n","The code that caused this warning is on line 389 of the file /usr/local/lib/python3.10/dist-packages/wikipedia/wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n","\n","  lis = BeautifulSoup(html).find_all('li')\n"]},{"output_type":"stream","name":"stdout","text":["Input has 61 tokens\n","Input has 1 spans\n","Span boundaries are [[0, 128]]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/wikipedia/wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n","\n","The code that caused this warning is on line 389 of the file /usr/local/lib/python3.10/dist-packages/wikipedia/wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n","\n","  lis = BeautifulSoup(html).find_all('li')\n"]},{"output_type":"stream","name":"stdout","text":["Input has 61 tokens\n","Input has 1 spans\n","Span boundaries are [[0, 128]]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/wikipedia/wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n","\n","The code that caused this warning is on line 389 of the file /usr/local/lib/python3.10/dist-packages/wikipedia/wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n","\n","  lis = BeautifulSoup(html).find_all('li')\n"]},{"output_type":"stream","name":"stdout","text":["Input has 61 tokens\n","Input has 1 spans\n","Span boundaries are [[0, 128]]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/wikipedia/wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n","\n","The code that caused this warning is on line 389 of the file /usr/local/lib/python3.10/dist-packages/wikipedia/wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n","\n","  lis = BeautifulSoup(html).find_all('li')\n"]},{"output_type":"stream","name":"stdout","text":["Input has 61 tokens\n","Input has 1 spans\n","Span boundaries are [[0, 128]]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/wikipedia/wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n","\n","The code that caused this warning is on line 389 of the file /usr/local/lib/python3.10/dist-packages/wikipedia/wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n","\n","  lis = BeautifulSoup(html).find_all('li')\n"]},{"output_type":"stream","name":"stdout","text":["Input has 61 tokens\n","Input has 1 spans\n","Span boundaries are [[0, 128]]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/wikipedia/wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n","\n","The code that caused this warning is on line 389 of the file /usr/local/lib/python3.10/dist-packages/wikipedia/wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n","\n","  lis = BeautifulSoup(html).find_all('li')\n"]},{"output_type":"stream","name":"stdout","text":["Input has 61 tokens\n","Input has 1 spans\n","Span boundaries are [[0, 128]]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/wikipedia/wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n","\n","The code that caused this warning is on line 389 of the file /usr/local/lib/python3.10/dist-packages/wikipedia/wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n","\n","  lis = BeautifulSoup(html).find_all('li')\n"]},{"output_type":"stream","name":"stdout","text":["Input has 61 tokens\n","Input has 1 spans\n","Span boundaries are [[0, 128]]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/wikipedia/wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n","\n","The code that caused this warning is on line 389 of the file /usr/local/lib/python3.10/dist-packages/wikipedia/wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n","\n","  lis = BeautifulSoup(html).find_all('li')\n"]},{"output_type":"stream","name":"stdout","text":["Input has 20 tokens\n","Input has 1 spans\n","Span boundaries are [[0, 128]]\n","Input has 20 tokens\n","Input has 1 spans\n","Span boundaries are [[0, 128]]\n","Input has 20 tokens\n","Input has 1 spans\n","Span boundaries are [[0, 128]]\n","Input has 10 tokens\n","Input has 1 spans\n","Span boundaries are [[0, 128]]\n","Input has 51 tokens\n","Input has 1 spans\n","Span boundaries are [[0, 128]]\n","Input has 51 tokens\n","Input has 1 spans\n","Span boundaries are [[0, 128]]\n","Input has 21 tokens\n","Input has 1 spans\n","Span boundaries are [[0, 128]]\n","Input has 21 tokens\n","Input has 1 spans\n","Span boundaries are [[0, 128]]\n","Input has 57 tokens\n","Input has 1 spans\n","Span boundaries are [[0, 128]]\n","Input has 57 tokens\n","Input has 1 spans\n","Span boundaries are [[0, 128]]\n","Input has 57 tokens\n","Input has 1 spans\n","Span boundaries are [[0, 128]]\n","Input has 57 tokens\n","Input has 1 spans\n","Span boundaries are [[0, 128]]\n","Input has 57 tokens\n","Input has 1 spans\n","Span boundaries are [[0, 128]]\n","Input has 57 tokens\n","Input has 1 spans\n","Span boundaries are [[0, 128]]\n","Input has 57 tokens\n","Input has 1 spans\n","Span boundaries are [[0, 128]]\n","Input has 43 tokens\n","Input has 1 spans\n","Span boundaries are [[0, 128]]\n","Input has 43 tokens\n","Input has 1 spans\n","Span boundaries are [[0, 128]]\n","Input has 43 tokens\n","Input has 1 spans\n","Span boundaries are [[0, 128]]\n","Input has 43 tokens\n","Input has 1 spans\n","Span boundaries are [[0, 128]]\n","Input has 43 tokens\n","Input has 1 spans\n","Span boundaries are [[0, 128]]\n","Input has 20 tokens\n","Input has 1 spans\n","Span boundaries are [[0, 128]]\n","Input has 20 tokens\n","Input has 1 spans\n","Span boundaries are [[0, 128]]\n","Input has 35 tokens\n","Input has 1 spans\n","Span boundaries are [[0, 128]]\n","Input has 35 tokens\n","Input has 1 spans\n","Span boundaries are [[0, 128]]\n","Input has 35 tokens\n","Input has 1 spans\n","Span boundaries are [[0, 128]]\n","Input has 35 tokens\n","Input has 1 spans\n","Span boundaries are [[0, 128]]\n","Input has 35 tokens\n","Input has 1 spans\n","Span boundaries are [[0, 128]]\n","Input has 12 tokens\n","Input has 1 spans\n","Span boundaries are [[0, 128]]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/wikipedia/wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n","\n","The code that caused this warning is on line 389 of the file /usr/local/lib/python3.10/dist-packages/wikipedia/wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n","\n","  lis = BeautifulSoup(html).find_all('li')\n"]},{"output_type":"stream","name":"stdout","text":["Input has 23 tokens\n","Input has 1 spans\n","Span boundaries are [[0, 128]]\n","Input has 23 tokens\n","Input has 1 spans\n","Span boundaries are [[0, 128]]\n","Input has 23 tokens\n","Input has 1 spans\n","Span boundaries are [[0, 128]]\n","Input has 23 tokens\n","Input has 1 spans\n","Span boundaries are [[0, 128]]\n","Input has 23 tokens\n","Input has 1 spans\n","Span boundaries are [[0, 128]]\n","Input has 23 tokens\n","Input has 1 spans\n","Span boundaries are [[0, 128]]\n","Input has 18 tokens\n","Input has 1 spans\n","Span boundaries are [[0, 128]]\n","Input has 18 tokens\n","Input has 1 spans\n","Span boundaries are [[0, 128]]\n","Input has 18 tokens\n","Input has 1 spans\n","Span boundaries are [[0, 128]]\n","Input has 18 tokens\n","Input has 1 spans\n","Span boundaries are [[0, 128]]\n","Input has 18 tokens\n","Input has 1 spans\n","Span boundaries are [[0, 128]]\n","Input has 61 tokens\n","Input has 1 spans\n","Span boundaries are [[0, 128]]\n","Input has 61 tokens\n","Input has 1 spans\n","Span boundaries are [[0, 128]]\n","Input has 61 tokens\n","Input has 1 spans\n","Span boundaries are [[0, 128]]\n","Input has 61 tokens\n","Input has 1 spans\n","Span boundaries are [[0, 128]]\n","Input has 61 tokens\n","Input has 1 spans\n","Span boundaries are [[0, 128]]\n","Input has 61 tokens\n","Input has 1 spans\n","Span boundaries are [[0, 128]]\n","Input has 61 tokens\n","Input has 1 spans\n","Span boundaries are [[0, 128]]\n","Input has 61 tokens\n","Input has 1 spans\n","Span boundaries are [[0, 128]]\n","Input has 61 tokens\n","Input has 1 spans\n","Span boundaries are [[0, 128]]\n","Input has 61 tokens\n","Input has 1 spans\n","Span boundaries are [[0, 128]]\n","Input has 61 tokens\n","Input has 1 spans\n","Span boundaries are [[0, 128]]\n","Input has 61 tokens\n","Input has 1 spans\n","Span boundaries are [[0, 128]]\n"]}]}]}